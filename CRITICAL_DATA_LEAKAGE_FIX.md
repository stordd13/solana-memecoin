# üö® CRITICAL DATA LEAKAGE FIX: Dead Token Constant Price Removal

## üìã **Problem Identified**

### **The Issue**
Dead tokens in the memecoin dataset contain **constant price periods** at the end of their timelines (‚â•1 hour of identical prices). If these constant periods are left in the training data, **forecasting models will learn a trivial pattern**:

```
Pattern Learned: "If price has been constant for X minutes ‚Üí predict the same constant price"
```

### **Impact on Model Performance**
- **Artificially inflated accuracy**: Models achieve 90%+ accuracy on dead tokens
- **Misleading metrics**: High accuracy doesn't reflect real predictive ability
- **False confidence**: Models appear to perform well when they're just memorizing constants
- **Poor generalization**: Models fail on real trading scenarios with price volatility

### **Example Scenario**
```
Dead Token Timeline:
Minutes 1-200:   Normal price movements [0.001, 0.002, 0.0015, ...]
Minutes 201-400: Constant price [0.0008, 0.0008, 0.0008, ...]  ‚Üê DATA LEAKAGE!

Model Learning:
- Sees 60 minutes of 0.0008 ‚Üí Predicts 0.0008 ‚úÖ (100% accurate but trivial)
- Real trading: Sees volatile prices ‚Üí Predicts wrong ‚ùå (poor real performance)
```

## ‚úÖ **Solution Implemented**

### **New Method: `_remove_death_period()`**
Added to the `CategoryAwareTokenCleaner` class in `data_cleaning/clean_tokens.py`

**What it does**:
1. **Detects** constant price periods ‚â•60 minutes at the end of token timelines
2. **Removes** the bulk of the constant period (keeps only 2 minutes for minimal context)
3. **Prevents** models from learning trivial constant-price patterns
4. **Logs** all modifications for transparency

### **Integration**
- **Automatically applied** to all dead tokens during `_minimal_cleaning()`
- **Only affects dead tokens** - other categories preserve their natural behavior
- **Conservative approach** - keeps only 2 minutes of constant price for minimal context

### **Parameters**
```python
min_constant_minutes = 60      # Only remove if ‚â•60 minutes constant
keep_constant_minutes = 2      # Keep only 2 minutes for minimal context
tolerance = 0.0001             # Allow tiny rounding differences
```

## üìä **Before vs After**

### **Before Fix**
```
Dead Token Data:
[normal_prices...] + [constant_price √ó 200 minutes]

Model Training:
- Learns: constant_pattern ‚Üí predict_constant ‚úÖ (easy 100% accuracy)
- Misleading performance metrics
```

### **After Fix**
```
Dead Token Data:
[normal_prices...] + [constant_price √ó 2 minutes]   # Bulk removed

Model Training:
- Must learn real price patterns (no easy constant predictions)
- Honest performance metrics
```

## üîß **Implementation Details**

### **Algorithm**
```python
def _remove_death_period(self, df, token_name):
    # 1. Sort by datetime
    df = df.sort('datetime')
    
    # 2. Work backwards to find constant period
    prices = df['price'].to_list()
    last_price = prices[-1]
    constant_count = 0
    
    for i in range(len(prices) - 1, -1, -1):
        if abs(prices[i] - last_price) < (last_price * 0.0001):
            constant_count += 1
        else:
            break
    
    # 3. Remove bulk if ‚â•60 minutes constant
    if constant_count >= 60:
        remove_count = constant_count - 2   # Keep only 2 for minimal context
        df_cleaned = df.head(df.height - remove_count)
        return df_cleaned, modifications
```

### **Logging**
Every modification is logged with:
```json
{
    "type": "death_period_removed",
    "constant_minutes_total": 120,
    "constant_minutes_removed": 90,
    "constant_minutes_kept": 2,
    "constant_price": 0.0008,
    "rows_before": 300,
    "rows_after": 210,
    "reason": "prevent_data_leakage_in_forecasting_models"
}
```

## üéØ **Benefits**

### **Model Integrity**
- ‚úÖ **Honest accuracy metrics** that reflect real predictive ability
- ‚úÖ **No trivial pattern learning** from constant price sequences
- ‚úÖ **Better generalization** to real trading scenarios
- ‚úÖ **Realistic performance expectations** for production deployment

### **Data Quality**
- ‚úÖ **Preserves natural market behavior** in active tokens
- ‚úÖ **Maintains minimal context** with only 2 minutes of constant price
- ‚úÖ **Conservative approach** - only removes obvious constant periods
- ‚úÖ **Transparent logging** of all modifications

## üöÄ **Usage**

### **Automatic Application**
The fix is **automatically applied** when cleaning dead tokens:

```bash
# This now includes death period removal for dead tokens
python data_cleaning/clean_tokens.py
```

### **Manual Testing**
```python
from data_cleaning.clean_tokens import CategoryAwareTokenCleaner

cleaner = CategoryAwareTokenCleaner()
cleaned_df, mods = cleaner._minimal_cleaning(dead_token_df, "TOKEN_NAME")

# Check if death period was removed
for mod in mods:
    if mod['type'] == 'death_period_removed':
        print(f"Removed {mod['constant_minutes_removed']} minutes of constant price")
```

## ‚ö†Ô∏è **Important Notes**

### **Only Affects Dead Tokens**
- **Normal behavior tokens**: No change (preserve natural volatility)
- **Extreme tokens**: No change (preserve extreme movements)
- **Gap tokens**: No change (preserve market behavior)
- **Dead tokens**: Remove constant periods to prevent leakage

### **Conservative Approach**
- **Minimum threshold**: 60 minutes constant before removal
- **Context preservation**: Always keep 2 minutes of constant price for minimal context
- **Tolerance**: Allows for tiny rounding differences (0.01%)

### **Transparency**
- **Full logging**: Every modification is recorded
- **Reversible**: Original data is preserved
- **Auditable**: Clear reasoning for each change

## üìà **Expected Impact**

### **Model Performance**
- **More realistic accuracy** on dead tokens (likely 60-70% instead of 90%+)
- **Better calibrated confidence** in predictions
- **Improved generalization** to live trading scenarios

### **Research Integrity**
- **Honest evaluation** of model capabilities
- **Reliable benchmarking** across different approaches
- **Trustworthy results** for production deployment

---

**This fix ensures that forecasting models learn genuine price prediction patterns rather than memorizing trivial constant sequences, leading to more reliable and trustworthy model performance metrics.** 