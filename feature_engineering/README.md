# ğŸ§® Feature Engineering Module

**Enhanced roadmap implementation with CLEAN ARCHITECTURE**

## ğŸš€ Quick Start

### **Unified Streamlit Dashboard**
```bash
# Run the comprehensive feature engineering dashboard
cd feature_engineering/
streamlit run app.py
```

**Single app handles everything:**
- ğŸ“ **Flexible folder browsing** (any data/ subfolder)
- ğŸ§® **Rolling feature engineering** (ML-safe only)
- ğŸ”— **Multi-token correlation analysis** with PCA
- ğŸ“Š **FFT cyclical pattern detection** 
- âš™ï¸ **Batch processing** for large-scale feature engineering
- ğŸ“‹ **Implementation report** with usage guide
- ğŸ§  **On-demand global features** (no redundancy)

## ğŸ§  **CLEAN ARCHITECTURE**

### **Core Principle: Separation of Concerns**
```
Rolling Features (ML-Safe)          Global Features (Analysis)
data/features/                  â†â†’  Computed on-demand in Streamlit
â”œâ”€â”€ normal_behavior/                 â”œâ”€â”€ Uses price_analysis.py
â”œâ”€â”€ tokens_with_extremes/            â”œâ”€â”€ No storage redundancy  
â””â”€â”€ dead_tokens/                     â””â”€â”€ Analysis-only features
```

### **Benefits:**
- âœ… **No redundancy** with data_analysis modules
- âœ… **Impossible to accidentally use global features in ML**
- âœ… **Cleaner separation** of rolling vs global features
- âœ… **Reduced storage** requirements
- âœ… **Leverages existing** price_analysis functionality

## ğŸ“Š **Analysis Types Available**

### 1. **ğŸ§® Feature Engineering**
- **Rolling Features**: MACD, Bollinger position, RSI, log-returns
- **Expanding Windows**: Volatility, Sharpe ratio, statistical moments
- **âœ… ML-Safe**: Only historical data, no future peeking
- **âŒ Global Features**: Computed on-demand, not stored

### 2. **ğŸ”— Correlation Analysis** 
- **Multi-method**: Pearson, Spearman, Kendall correlations
- **PCA Analysis**: Explained variance ratios for redundancy detection
- **Log-returns**: Option to use log-returns vs prices
- **Robust Scaling**: Per-token normalization option
- **Rolling Correlations**: Time-varying correlation analysis

### 3. **ğŸ“Š FFT Analysis**
- **Multi-token**: Sequential analysis of multiple tokens
- **Window Functions**: Hamming, Hann, Blackman for spectral analysis
- **Pattern Detection**: Short-term, medium-term, long-term cycles
- **Advanced Options**: Detrending, phase analysis, normalization
- **Comparison Mode**: Compare FFT patterns between token groups

### 4. **âš™ï¸ Batch Processing**
- **Rolling Features Only**: No global features computed
- **Configurable**: Select technical indicators and window sizes
- **Progress Tracking**: Real-time progress bars
- **Category-aware**: Maintains folder structure

### 5. **ğŸ§  On-Demand Global Features**
- **Uses price_analysis.py**: Leverages existing analysis functionality
- **No Storage**: Computed when needed, not pre-stored
- **Complete Analysis**: Total returns, drawdowns, pattern classification
- **No Redundancy**: Eliminates duplicate computation

## ğŸ’¾ **Data Architecture**

### **Clean Separation:**
```python
# âœ… ROLLING FEATURES (data/features/)
- log_returns, rolling_volatility, rolling_sharpe
- macd_line, macd_signal, bb_position
- rsi_values, atr_values
- rolling_skewness, rolling_kurtosis

# ğŸ§  GLOBAL FEATURES (computed on-demand)
- total_return_pct, max_drawdown_pct  
- global_volatility, pattern_classification
- FFT spectral_entropy, dominant_periods
- Multi-granularity candlestick patterns
```

### **ML Training Pipeline:**
```bash
# 1. Feature Engineering (rolling only)
python feature_engineering/advanced_feature_engineering.py

# 2. ML Training (uses only rolling features)
python ML/directional_models/train_lightgbm_model.py
```

### **Analysis Pipeline:**
```bash
# 1. Streamlit Analysis (computes global on-demand)
streamlit run feature_engineering/app.py

# 2. Select token â†’ global features computed automatically
# 3. No storage waste, no redundancy
```

## ğŸ”¬ **Technical Implementation**

### **Rolling Feature Engineering**
```python
from feature_engineering import AdvancedFeatureEngineer, create_rolling_features_safe

# Only rolling features saved
engineer = AdvancedFeatureEngineer()
features = engineer.create_comprehensive_features(df, token_name)

# Clean architecture: saves only ML-safe features
save_features_to_files(features_dict, token_paths)  # Rolling only
```

### **On-Demand Global Features**
```python
from feature_engineering.app import compute_global_features_on_demand

# Computed when needed using existing price_analysis
global_features = compute_global_features_on_demand(df, token_name)
# Uses: data_analysis.price_analysis.PriceAnalyzer
```

### **Multi-Token Correlation**
```python
from feature_engineering import TokenCorrelationAnalyzer

analyzer = TokenCorrelationAnalyzer()
results = analyzer.analyze_token_correlations(
    token_data, 
    use_log_returns=True,
    use_robust_scaling=True,
    min_overlap=100
)
```

## ğŸ¯ **Usage Examples**

### **1. Single Token Analysis**
```bash
streamlit run app.py
# â†’ Select token
# â†’ Check "Show Global Features" for on-demand computation
# â†’ Rolling features always available
```

### **2. Batch Feature Engineering**
```python
python advanced_feature_engineering.py
# â†’ Processes all cleaned tokens
# â†’ Saves ONLY rolling features
# â†’ No global feature storage
```

### **3. Multi-Token Correlation** 
```bash
streamlit run app.py
# â†’ Select "Correlation Analysis"
# â†’ Choose multiple tokens
# â†’ PCA redundancy detection included
```

## ğŸ›¡ï¸ **Data Leakage Prevention**

### **Safe Features (Stored):**
- âœ… Rolling windows (expanding/fixed)
- âœ… Technical indicators (MACD, RSI, BB)
- âœ… Lag features and momentum
- âœ… Expanding statistical moments

### **Unsafe Features (On-Demand Only):**
- ğŸ§  Total returns (uses final price)
- ğŸ§  Max drawdowns (uses min/max across series)  
- ğŸ§  FFT spectral entropy (uses entire series)
- ğŸ§  Pattern classification (uses full dataset)

## ğŸ“ **File Structure**

```
feature_engineering/
â”œâ”€â”€ app.py                           # ğŸ¯ Main Streamlit dashboard
â”œâ”€â”€ advanced_feature_engineering.py  # ğŸ”„ Rolling feature extraction
â”œâ”€â”€ correlation_analysis.py          # ğŸ”— Multi-token relationships
â”œâ”€â”€ __init__.py                      # ğŸ“¦ Package initialization
â””â”€â”€ README.md                        # ğŸ“š This documentation

data/
â”œâ”€â”€ features/                        # ğŸ”„ Rolling features (ML-safe)
â”‚   â”œâ”€â”€ normal_behavior_tokens/
â”‚   â”œâ”€â”€ tokens_with_extremes/
â”‚   â””â”€â”€ dead_tokens/
â””â”€â”€ [no global_features directory]   # ğŸ§  Computed on-demand
```

## ğŸ† **Architecture Benefits**

### **Before (Redundant):**
- âŒ Global features stored in feature_engineering 
- âŒ Same features computed in data_analysis
- âŒ Storage waste and confusion
- âŒ Risk of using global features in ML

### **After (Clean):**
- âœ… Rolling features only in feature_engineering
- âœ… Global features on-demand from price_analysis
- âœ… No redundancy or storage waste
- âœ… Impossible to use global features in ML by accident

## ğŸš€ **Migration Guide**

If you have existing global feature files, they can be safely deleted:
```bash
# Remove old global features (now computed on-demand)
rm -rf data/global_features_analysis_only/

# Keep rolling features (ML-safe)
# data/features/ directory remains unchanged
```

## ğŸ§ª **Testing the Clean Architecture**

```python
# Test rolling features
from feature_engineering import create_rolling_features_safe
rolling_df = create_rolling_features_safe(df, token_name)
print(f"Rolling features: {rolling_df.columns}")

# Test on-demand global features  
from feature_engineering.app import compute_global_features_on_demand
global_features = compute_global_features_on_demand(df, token_name)
print(f"Global computed: {global_features['computed_on_demand']}")
```

---

## ğŸ“ **Support**

The clean architecture ensures:
- ğŸ¯ **Single responsibility**: Each module has a clear purpose
- ğŸ”’ **Data safety**: Impossible to leak global features into ML
- ğŸ“Š **No redundancy**: Global features computed once when needed
- ğŸ§  **Leverages existing code**: Uses proven price_analysis functionality 